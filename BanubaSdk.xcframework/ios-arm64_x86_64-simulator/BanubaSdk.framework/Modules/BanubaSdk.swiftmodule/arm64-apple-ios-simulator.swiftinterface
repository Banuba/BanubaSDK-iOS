// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 6.0.2 effective-5.10 (swiftlang-6.0.2.1.2 clang-1600.0.26.4)
// swift-module-flags: -target arm64-apple-ios15.0-simulator -enable-objc-interop -enable-library-evolution -swift-version 5 -enforce-exclusivity=checked -O -enable-bare-slash-regex -module-name BanubaSdk
// swift-module-flags-ignorable: -no-verify-emitted-module-interface
import AVKit
import Accelerate
import BNBSdkApi
import BNBSdkCore
@_exported import BanubaSdk
import BanubaUtilities
import CoreMotion
import CoreVideo
import Foundation
import MediaPlayer
import Metal
import MetalKit
import QuartzCore
import Swift
import UIKit
import _Concurrency
import _StringProcessing
import _SwiftConcurrencyShims
import os.log
import os
@objc @_hasMissingDesignatedInitializers public class PIPPlayer : BanubaSdk.PIPShapeDrawer {
  final public let assetNaturalSize: CoreFoundation.CGSize
  public var currentTime: CoreMedia.CMTime {
    get
  }
  public var isPlaying: Swift.Bool {
    get
  }
  public var isReadyToProvideData: Swift.Bool {
    get
  }
  public init(asset: AVFoundation.AVAsset, firstFrameTime: CoreMedia.CMTime)
  @objc deinit
  public func setVolume(_ volume: Swift.Float)
  public func startPlaying()
  public func stopPlaying()
  public func seek(to time: Foundation.TimeInterval)
  public func draw(renderEncoder: any Metal.MTLRenderCommandEncoder, fullRenderSize: CoreFoundation.CGSize, relativeLeftTopPoint: CoreFoundation.CGPoint, scale: CoreFoundation.CGFloat)
  @objc override dynamic public func observeValue(forKeyPath keyPath: Swift.String?, of object: Any?, change: [Foundation.NSKeyValueChangeKey : Any]?, context: Swift.UnsafeMutableRawPointer?)
}
@objc public enum EffectPlayerRenderMode : Swift.Int {
  case photo
  case video
  public init?(rawValue: Swift.Int)
  public typealias RawValue = Swift.Int
  public var rawValue: Swift.Int {
    get
  }
}
@_inheritsConvenienceInitializers @objc public class EffectPlayerConfiguration : ObjectiveC.NSObject {
  @_inheritsConvenienceInitializers @objc public class Defaults : ObjectiveC.NSObject {
    @objc public static let videoSessionPreset: AVFoundation.AVCaptureSession.Preset
    @objc public static let photoSessionPreset: AVFoundation.AVCaptureSession.Preset
    @objc public static let photoRenderSize: CoreFoundation.CGSize
    @objc public static let videoRenderSize: CoreFoundation.CGSize
    @objc public static let defaultFrameRate: Swift.Int
    @objc override dynamic public init()
    @objc deinit
  }
  @objc final public let cameraMode: BanubaSdk.CameraSessionType
  @objc public var renderContentMode: BanubaSdk.RenderContentMode
  @objc public var renderSize: CoreFoundation.CGSize
  @objc public var captureSessionPreset: AVFoundation.AVCaptureSession.Preset
  @objc public var preferredRenderFrameRate: Swift.Int
  @objc public var shouldAutoStartOnEnterForeground: Swift.Bool
  @objc public var isMirrored: Swift.Bool
  @objc public var flipVertically: Swift.Bool
  @objc public var delayedCameraInitialization: Swift.Bool
  @objc public var orientation: BNBSdkCore.BNBCameraOrientation
  @objc public var notificationCenter: Foundation.NotificationCenter
  @objc override convenience dynamic public init()
  @objc convenience public init(renderMode: BanubaSdk.EffectPlayerRenderMode, renderContentMode: BanubaSdk.RenderContentMode = .resizeAspect, orientation: BNBSdkCore.BNBCameraOrientation = .deg90, preferredRenderFrameRate: Swift.Int = EffectPlayerConfiguration.Defaults.defaultFrameRate, shouldAutoStartOnEnterForeground: Swift.Bool = true, isMirrored: Swift.Bool = false, delayedCameraInitialization: Swift.Bool = false, notificationCenter: Foundation.NotificationCenter = NotificationCenter.default)
  @objc public init(cameraMode: BanubaSdk.CameraSessionType, renderContentMode: BanubaSdk.RenderContentMode = .resizeAspect, renderSize: CoreFoundation.CGSize, captureSessionPreset: AVFoundation.AVCaptureSession.Preset, orientation: BNBSdkCore.BNBCameraOrientation = .deg90, preferredRenderFrameRate: Swift.Int = EffectPlayerConfiguration.Defaults.defaultFrameRate, shouldAutoStartOnEnterForeground: Swift.Bool = true, isMirrored: Swift.Bool = false, flipVertically: Swift.Bool = true, delayedCameraInitialization: Swift.Bool = false, notificationCenter: Foundation.NotificationCenter = NotificationCenter.default)
  @objc deinit
}
@_inheritsConvenienceInitializers @objc public class BanubaCameraModule : ObjectiveC.NSObject {
  @objc public var isPIPSession: Swift.Bool
  @objc public var pipVideoURL: Foundation.URL?
  @objc public var pipSwitchSetting: BanubaVideoEditorCore.PIPSwitchLayoutSetting?
  @objc public var pipPlayerSetting: BanubaVideoEditorCore.PIPPlayerLayoutSetting?
  @objc public var pipCameraSetting: BanubaVideoEditorCore.PIPCameraLayoutSetting?
  @objc public var pipVideoContentMode: BanubaVideoEditorCore.PIPVideoContentMode
  @objc public var isRenderLoopRunning: Swift.Bool {
    @objc get
  }
  @objc public var isCameraEnabled: Swift.Bool {
    @objc get
    @objc set
  }
  public static var additionalEffectsPaths: [Swift.String]?
  @objc public var isLoaded: Swift.Bool
  @objc public var inputDelegate: (any BanubaVideoEditorCore.SDKInputServicingDelegate)?
  public static var videoSize: CoreFoundation.CGSize! {
    get
  }
  public static var videoPreset: AVFoundation.AVCaptureSession.Preset! {
    get
  }
  @objc public static func initialize(sdkToken: Swift.String, videoSize: CoreFoundation.CGSize, videoPreset: AVFoundation.AVCaptureSession.Preset, useHEVCCodecIfPossibleForRecorder: Swift.Bool, isMirrored: Swift.Bool, additionalEffectsPaths: [Swift.String]? = nil)
  @objc required override dynamic public init()
  public enum MethodInJson : Swift.String {
    case changeAxis
    case runScan
    case resetScan
    case onStop
    case onTouchesBegan
    case onFinish
    case setBgTexture
    case setBgVideo
    case playVideo
    case pauseVideo
    case rotateBg
    case playVideoRange
    case stopVideo
    case stopMusic
    case hideInteractive
    case updatePreview
    case enableBlur
    public init?(rawValue: Swift.String)
    public typealias RawValue = Swift.String
    public var rawValue: Swift.String {
      get
    }
  }
  @objc deinit
}
extension BanubaSdk.BanubaCameraModule : BanubaVideoEditorCore.CameraModule {
  @objc dynamic public var renderQueue: Dispatch.DispatchQueue? {
    @objc get
  }
  public var pipRenderSize: CoreFoundation.CGSize {
    get
  }
  @objc dynamic public var autoStart: Swift.Bool {
    @objc get
    @objc set
  }
  @objc dynamic public var isPIPPlayerReadyToProvideData: Swift.Bool {
    @objc get
  }
  @objc dynamic public var currentPiPVideoTime: CoreMedia.CMTime {
    @objc get
  }
  @objc dynamic public func addFPSListener(_ listener: ((_ fpsInfo: Foundation.NSAttributedString) -> Swift.Void)?)
  @objc dynamic public func setMaxFaces(facesCount: Swift.Int32)
  @objc dynamic public func setup()
  @objc dynamic public func destroy()
  @objc dynamic public func takeSnapshot(isFrontCameraMirrored: Swift.Bool, handler: @escaping (UIKit.UIImage?) -> Swift.Void)
  @objc dynamic public func start(completion: @escaping () -> Swift.Void)
  @objc dynamic public func stop(completion: (() -> Swift.Void)?)
  @objc dynamic public func setRenderTarget(view: UIKit.UIView)
  @objc dynamic public func removeRenderTarget()
  @objc dynamic public func getRendererView() -> UIKit.UIView
  @objc dynamic public func startRenderLoop()
  @objc dynamic public func stopRenderLoop()
}
extension BanubaSdk.BanubaCameraModule {
  @objc dynamic public func rewindPIPPlayer()
  @objc dynamic public func resetPIPPlayerPlayback()
  @objc dynamic public func resumePIPPlayer()
  @objc dynamic public func startPIPPlayer()
  @objc dynamic public func stopPIPPlayer()
  @objc dynamic public func setPIPPlayerVolume(_ volume: Swift.Float)
  @objc dynamic public func setupPIPSession(withVideoURL url: Foundation.URL, playerSetting: BanubaVideoEditorCore.PIPPlayerLayoutSetting, cameraSetting: BanubaVideoEditorCore.PIPCameraLayoutSetting, switchSetting: BanubaVideoEditorCore.PIPSwitchLayoutSetting)
  @objc dynamic public func stopPIPSession()
  @objc dynamic public func startPIPSessionIfNeeded(withSetting setting: BanubaVideoEditorCore.PIPPlayerLayoutSetting, completion: (() -> Swift.Void)?)
  @objc dynamic public func applyVideoContentMode(_ contentMode: BanubaVideoEditorCore.PIPVideoContentMode)
  @objc dynamic public func applyPIPLayoutSetting(_ layoutSettings: BanubaVideoEditorCore.PIPLayoutSettings)
}
extension BanubaSdk.BanubaCameraModule {
  @objc dynamic public func startMultiCamMixing(isPresenterMode: Swift.Bool, completion: (() -> Swift.Void)?)
  @objc dynamic public func stopMultiCamMixing(completion: (() -> Swift.Void)?)
}
extension BanubaSdk.BanubaCameraModule : BanubaVideoEditorCore.SDKInputServicing {
  @objc dynamic public var zoomFactor: Swift.Float {
    @objc get
  }
  @objc dynamic public var defaultZoom: Swift.Float {
    @objc get
  }
  @objc dynamic public var isFrontCamera: Swift.Bool {
    @objc get
  }
  @objc dynamic public var currentCameraSessionType: BanubaVideoEditorCore.CameraModuleSessionType {
    @objc get
  }
  @objc dynamic public var isMultiCamSupported: Swift.Bool {
    @objc get
  }
  @objc dynamic public var isMultiCamEnabled: Swift.Bool {
    @objc get
    @objc set
  }
  @objc dynamic public func focus(at point: CoreFoundation.CGPoint, useContinuousDetection: Swift.Bool)
  @objc dynamic public func setZoomFactor(_ zoomFactor: Swift.Float) -> Swift.Float
  @objc dynamic public func toggleCamera(completion: @escaping () -> ())
  @objc dynamic public func startCamera()
  @objc dynamic public func startAudioCapturing()
  @objc dynamic public func stopAudioCapturing()
  @objc dynamic public func setCameraSessionType(_ type: BanubaVideoEditorCore.CameraModuleSessionType)
  @objc dynamic public func setTorch(mode: AVFoundation.AVCaptureDevice.TorchMode) -> AVFoundation.AVCaptureDevice.TorchMode
  @objc dynamic public func toggleTorch() -> AVFoundation.AVCaptureDevice.TorchMode
}
extension BanubaSdk.BanubaCameraModule : BanubaVideoEditorCore.SDKOutputServicing {
  @objc dynamic public var isRecording: Swift.Bool {
    @objc get
  }
  @objc dynamic public var isEnoughDiskSpaceForRecording: Swift.Bool {
    @objc get
  }
  @objc dynamic public func startVideoCapturing(fileURL: Foundation.URL?, startTimeForVideoTexture: Swift.Double, externalAudioConfiguration: BanubaVideoEditorCore.ExternalAudioConfiguration?, progress: @escaping (CoreMedia.CMTime) -> Swift.Void, didStart: (() -> Swift.Void)?, shouldSkipFrame: (() -> Swift.Bool)?, periodicProgressTimeInterval: Foundation.TimeInterval, totalDuration: Foundation.TimeInterval, itemDuration: Foundation.TimeInterval, completion: @escaping (Swift.Bool, (any Swift.Error)?) -> Swift.Void)
  @objc dynamic public func stopVideoCapturing(cancel: Swift.Bool)
}
extension BanubaSdk.BanubaCameraModule : BanubaVideoEditorCore.SDKEffectsServicing {
  @objc dynamic public func enableBlur()
  @objc dynamic public var isMaskLoaded: Swift.Bool {
    @objc get
  }
  @objc dynamic public var currentMaskName: Swift.String? {
    @objc get
  }
  @objc dynamic public func loadMask(name: Swift.String, synchronous: Swift.Bool)
  @objc dynamic public func callEffectMethod(_ method: Swift.String)
  @objc dynamic public func unloadMask()
  @objc dynamic public func removeAllFilters()
  @objc dynamic public func applyFilter(_ filter: any BanubaVideoEditorCore.RenderEffect)
  @objc dynamic public func removeFilter(_ filter: any BanubaVideoEditorCore.RenderEffect)
  @objc dynamic public func effectsPaths() -> [Swift.String]
  @objc dynamic public func effectDidBeginApplying()
  @objc dynamic public func effectDidEndApplying()
  @objc dynamic public func effectDidResetApplying()
  @objc dynamic public func effectDidChangeState()
  @objc dynamic public func setDoubleTapGestureEnabled(_ isEnabled: Swift.Bool)
}
extension BanubaSdk.BanubaCameraModule : BanubaVideoEditorCore.SDKBeautyEffectManaging {
  @objc dynamic public var isBeautyEnabled: Swift.Bool {
    @objc get
  }
  @objc dynamic public func enableBeauty() async
  @objc dynamic public func disableBeauty()
  @objc dynamic public var intensity: Swift.Double {
    @objc get
    @objc set
  }
  @objc dynamic public func resetIntensity()
}
extension BanubaSdk.BanubaCameraModule : BanubaVideoEditorCore.SDKBackgroundEffectManaging {
  @objc dynamic public var isBackgroundEnabled: Swift.Bool {
    @objc get
  }
  @objc dynamic public var embeddedImages: [BanubaVideoEditorCore.EmbeddedBackgroundImage] {
    @objc get
  }
  @objc dynamic public func enableBackground() async
  @objc dynamic public func disableBackground()
  @objc dynamic public func effectAddImageTexture(image: UIKit.UIImage, backgroundColor: UIKit.UIColor)
  @objc dynamic public func stopVideoTextureIfNeeded()
  @objc dynamic public func effectAddVideoTexture(asset: AVFoundation.AVURLAsset, backgroundColor: UIKit.UIColor)
  @objc dynamic public func effectReloadTexturePreview(startTime: Foundation.TimeInterval, endTime: Foundation.TimeInterval, itemDuration: Foundation.TimeInterval)
  @objc dynamic public func enableBackgroundBlur()
  @objc dynamic public func unloadEffectTexture()
  @objc dynamic public func setCameraVideoFrame(_ frame: CoreFoundation.CGRect)
  @objc dynamic public func resetCameraVideoFrame()
}
extension BanubaSdk.BanubaCameraModule : BanubaSdk.BanubaSdkManagerDelegate {
  @objc dynamic public func willOutput(pixelBuffer: CoreVideo.CVPixelBuffer)
  @objc dynamic public func willPresent(changedPixelBuffer: CoreVideo.CVPixelBuffer?)
  @objc dynamic public func didProduceCapturingPerfomanceInfo(_ info: BanubaSdk.CapturingPerfomanceInfo)
}
@_hasMissingDesignatedInitializers @objc public class WatermarkDrawSettings : ObjectiveC.NSObject {
  final public let translatePos: CoreFoundation.CGPoint
  final public let rotationAngle: CoreFoundation.CGFloat
  final public let drawRect: CoreFoundation.CGRect
  @objc deinit
}
@objc public enum WatermarkCornerPosition : Swift.Int {
  case topLeft
  case topRight
  case bottomRight
  case bottomLeft
  public init?(rawValue: Swift.Int)
  public typealias RawValue = Swift.Int
  public var rawValue: Swift.Int {
    get
  }
}
@objc public class WatermarkInfo : ObjectiveC.NSObject {
  @objc public init(image: UIKit.UIImage, corner: BanubaSdk.WatermarkCornerPosition, offset: CoreFoundation.CGPoint, targetWidth: CoreFoundation.CGFloat)
  @objc public init(image: UIKit.UIImage, corner: BanubaSdk.WatermarkCornerPosition, offset: CoreFoundation.CGPoint, targetNormalizedWidth: CoreFoundation.CGFloat)
  @objc public init(image: UIKit.UIImage, normalizedPosition: CoreFoundation.CGPoint, targetWidth: CoreFoundation.CGFloat)
  @objc public init(image: UIKit.UIImage, normalizedPosition: CoreFoundation.CGPoint, targetNormalizedWidth: CoreFoundation.CGFloat)
  @objc public func drawSettingsWithBoundsSize(_ boundsSize: CoreFoundation.CGSize, outputSettings: BanubaVideoEditorCore.VEOutputSettings) -> BanubaSdk.WatermarkDrawSettings
  @objc deinit
}
@objc @_inheritsConvenienceInitializers @_hasMissingDesignatedInitializers public class MultiCamMixer : BanubaSdk.PIPShapeDrawer {
  public func draw(renderEncoder: any Metal.MTLRenderCommandEncoder, fullRenderSize: CoreFoundation.CGSize, relativeLeftTopPoint: CoreFoundation.CGPoint, scale: CoreFoundation.CGFloat)
  @objc deinit
}
@_hasMissingDesignatedInitializers public class MetalVerticesAndUVData {
  public static let quadVertexData: [Swift.Float]
  public static func quadVertexData(scale: Swift.Float) -> [Swift.Float]
  public static let defaultTextureCoordinates: [Swift.Float]
  @objc deinit
}
@objc public protocol BanubaSdkManagerDelegate {
  @objc func willPresent(changedPixelBuffer: CoreVideo.CVPixelBuffer?)
  @objc func willOutput(pixelBuffer: CoreVideo.CVPixelBuffer)
  @objc func didProduceCapturingPerfomanceInfo(_ info: BanubaSdk.CapturingPerfomanceInfo)
}
@_hasMissingDesignatedInitializers @objc public class CapturingPerfomanceInfo : ObjectiveC.NSObject {
  final public let cameraFPS: Swift.Float
  final public let recognizerFPS: Swift.Float
  final public let renderFPS: Swift.Float
  final public let systemPressureStateLevel: Swift.String
  @objc deinit
}
@_inheritsConvenienceInitializers @objc public class BanubaSdkManager : ObjectiveC.NSObject {
  @objc weak public var delegate: (any BanubaSdk.BanubaSdkManagerDelegate)?
  @objc public var effectPlayer: BNBSdkCore.BNBEffectPlayer? {
    get
  }
  @objc public var faceOrientation: Swift.Int
  @objc public var isCameraEnabled: Swift.Bool
  @objc public var effectManager: BNBSdkCore.BNBEffectManager? {
    @objc get
  }
  @objc public var autoRotationEnabled: Swift.Bool {
    @objc get
    @objc set
  }
  @objc public func loadEffect(_ effectUrl: Swift.String, synchronous: Swift.Bool = false) -> BNBSdkCore.BNBEffect?
  @objc public var currentEffect: BNBSdkCore.BNBEffect? {
    @objc get
  }
  @objc public func setMaxFaces(_ maxFaces: Swift.Int32)
  @objc public var input: any BanubaSdk.InputServicing {
    @objc get
    @objc set
  }
  @objc public var output: (any BanubaSdk.OutputServicing)? {
    @objc get
  }
  @objc public var renderTarget: BanubaSdk.RenderTarget?
  @objc public var playerConfiguration: BanubaSdk.EffectPlayerConfiguration? {
    @objc get
  }
  @objc public func setRenderTarget(view: BanubaSdk.EffectPlayerView, playerConfiguration: BanubaSdk.EffectPlayerConfiguration?)
  @objc public func setRenderTarget(layer: QuartzCore.CAMetalLayer, renderMode: BanubaSdk.EffectPlayerRenderMode, contentMode: BanubaSdk.RenderContentMode = .resizeAspectFill)
  @objc public func setRenderTarget(layer: QuartzCore.CAMetalLayer, contentMode: BanubaSdk.RenderContentMode = .resizeAspectFill, playerConfiguration: BanubaSdk.EffectPlayerConfiguration?)
  @objc public func removeRenderTarget()
  public var editingImageFrameData: BNBSdkCore.BNBFrameData? {
    get
  }
  @objc public var renderThread: Foundation.Thread? {
    @objc get
  }
  @objc public var shouldAutoStartOnEnterForeground: Swift.Bool
  @objc public var isLoaded: Swift.Bool {
    get
  }
  @objc override dynamic public init()
  @objc public class func initialize(resourcePath: [Swift.String] = [], clientTokenString: Swift.String, logLevel: BNBSdkCore.BNBSeverityLevel = .info)
  @objc public class func deinitialize()
  @objc deinit
  @objc public func setup(configuration: BanubaSdk.EffectPlayerConfiguration)
  @objc public func destroy()
  @objc public static func scaleBeforeProcessing(_ buffer: CoreVideo.CVPixelBuffer?) -> CoreVideo.CVPixelBuffer?
  @objc public var isDrawOnDemandMode: Swift.Bool {
    get
  }
  @objc public var frameOnDemandRendered: Swift.Bool {
    get
  }
  @objc public func setDrawOnDemandMode(_ mode: Swift.Bool)
  @objc public func requestFrameDraw()
}
@objc extension BanubaSdk.BanubaSdkManager : BanubaSdk.InputServiceDelegate {
  @objc dynamic public func push(cmBuffer: CoreMedia.CMSampleBuffer)
  @objc dynamic public func push(cvBuffer: CoreVideo.CVPixelBuffer, isMainCamera: Swift.Bool)
}
@objc extension BanubaSdk.BanubaSdkManager {
  @objc dynamic public func startEffectPlayer()
  @objc dynamic public func stopEffectPlayer()
  @objc dynamic public func destroyEffectPlayer()
  @objc dynamic public func startEditingImage(_ image: UIKit.UIImage, recognizerIterations: Foundation.NSNumber? = nil, imageOrientation: BNBSdkCore.BNBCameraOrientation = .deg0, requireMirroring: Swift.Bool = false, faceOrientation: Swift.Int = 0, fieldOfView: Swift.Float = 60, resetEffect: Swift.Bool = false, completion: ((Swift.Int, CoreFoundation.CGRect) -> Swift.Void)? = nil)
  @objc dynamic public func updateEditingFrameWithImage(_ image: UIKit.UIImage, imageOrientation: BNBSdkCore.BNBCameraOrientation = .deg0, requireMirroring: Swift.Bool = false, faceOrientation: Swift.Int = 0, fieldOfView: Swift.Float = 60, completion: ((Swift.Bool) -> Swift.Void)? = nil)
  @objc dynamic public func captureEditedImage(imageOrientation: BNBSdkCore.BNBCameraOrientation = .deg0, resetEffect: Swift.Bool = false, completion: @escaping (UIKit.UIImage?) -> Swift.Void)
  @objc dynamic public func stopEditingImage(startCameraInput: Swift.Bool = false)
  @objc dynamic public func makeCameraPhoto(cameraSettings: BanubaSdk.CameraPhotoSettings, flipFrontCamera: Swift.Bool = false, srcImageHandler: ((CoreVideo.CVPixelBuffer) -> Swift.Void)? = nil, completion: @escaping (UIKit.UIImage?) -> Swift.Void)
  @objc dynamic public func processImageData(_ inputData: CoreVideo.CVImageBuffer, orientation: BNBSdkCore.BNBCameraOrientation = .deg0, faceOrientation: Swift.Int = 0, fieldOfView: Swift.Float = 60, isMirrored: Swift.Bool = false, completion: @escaping (UIKit.UIImage?) -> Swift.Void)
  @objc dynamic public func processImageData(_ imputImage: UIKit.UIImage, orientation: BNBSdkCore.BNBCameraOrientation = .deg0, fieldOfView: Swift.Float = 60, isMirrored: Swift.Bool = false, completion: @escaping (UIKit.UIImage?) -> Swift.Void)
  @objc dynamic public func configureWatermark(_ watermarkInfo: BanubaSdk.WatermarkInfo)
  @objc dynamic public func removeWatermark()
  @objc dynamic public func startVideoProcessing(width: Swift.UInt, height: Swift.UInt, orientation: BNBSdkCore.BNBCameraOrientation = .deg0, resetEffect: Swift.Bool = false)
  @objc dynamic public func stopVideoProcessing(resetEffect: Swift.Bool = false)
  @objc dynamic public func processVideoFrame(from: CoreVideo.CVPixelBuffer, to: CoreVideo.CVPixelBuffer, timeNs: Swift.Int64, iterations: Foundation.NSNumber? = nil, cameraOrientation: BNBSdkCore.BNBCameraOrientation = .deg0, requireMirroring: Swift.Bool = false, faceOrientation: Swift.Int = 0, fieldOfView: Swift.Float = 60)
  @objc dynamic public var imageOrientationForCameraPhoto: BNBSdkCore.BNBCameraOrientation {
    @objc get
  }
}
extension BanubaSdk.BanubaSdkManager : BNBSdkCore.BNBCameraPoiListener {
  @objc dynamic public func onCameraPoiChanged(_ x: Swift.Float, y: Swift.Float)
}
extension BanubaSdk.BanubaSdkManager : BNBSdkCore.BNBFaceNumberListener {
  @objc dynamic public func onFaceNumberChanged(_ faceNumber: Swift.Int32)
}
extension BanubaSdk.BanubaSdkManager : BNBSdkCore.BNBFrameDurationListener {
  public func listenFrameDuration()
  @objc dynamic public func onRecognizerFrameDurationChanged(_ instant: Swift.Float, averaged: Swift.Float)
  @objc dynamic public func onCameraFrameDurationChanged(_ instant: Swift.Float, averaged: Swift.Float)
  @objc dynamic public func onRenderFrameDurationChanged(_ instant: Swift.Float, averaged: Swift.Float)
}
extension BanubaSdk.BanubaSdkManager {
  public var isPiPPlayerLandscapeOrientation: Swift.Bool? {
    get
  }
  public var isPIPPlayerReadyToProvideData: Swift.Bool? {
    get
  }
  public func createPIPPlayer(withVideoURL url: Foundation.URL, firstFrameTime: CoreMedia.CMTime, completion: (() -> Swift.Void)?)
  public func destroyPIPPlayer()
  public func startPIPMixer(isPresenterMode: Swift.Bool, completion: (() -> Swift.Void)?)
  public func stopPIPMixer(completion: (() -> Swift.Void)?)
  public func startPIPPlayer()
  public func stopPIPPlayer()
  public func setPIPPlayerVolume(_ volume: Swift.Float)
  public func seekPIPPlayer(to time: Foundation.TimeInterval)
  public func setRenderBehaviour(_ renderBehaviour: BanubaSdk.RenderBehavior)
  public func setPIPPlayerShapeType(_ shapeType: BanubaSdk.PIPShapeBuilder.PIPShapeType)
  public func setPIPMixerShapeType(_ shapeType: BanubaSdk.PIPShapeBuilder.PIPShapeType)
  public func setRenderTargetShapeType(_ type: BanubaSdk.PIPShapeBuilder.PIPShapeType)
  public func setPIPPlayer(centerPoint point: CoreFoundation.CGPoint)
  public func setPIPMixer(centerPoint point: CoreFoundation.CGPoint)
  public func resetSplitRender()
  public func setSplitRender()
}
extension BanubaSdk.BanubaSdkManager {
  @objc public class BanubaVisualClipVideo : ObjectiveC.NSObject {
    final public let path: Swift.String
    final public let startPosition: Swift.Float
    final public let duration: Swift.Float
    @objc public init(path: Swift.String, startPosition: Swift.Float, duration: Swift.Float)
    @objc deinit
  }
  @objc public static func createAutoCutVideos(with musicDbPath: Swift.String, effectsTemplatesPath: Swift.String, videos: [BanubaSdk.BanubaSdkManager.BanubaVisualClipVideo], numFrames: Swift.Int, resultSize: Swift.Int, cancellation: @escaping ((Swift.Double) -> Swift.Bool)) -> [Swift.String]?
}
extension BanubaSdk.BanubaSdkManager : BanubaUtilities.AppStateObserverDelegate {
  @objc dynamic public func applicationWillResignActive(_ appStateObserver: BanubaUtilities.AppStateObserver)
  @objc dynamic public func applicationDidBecomeActive(_ appStateObserver: BanubaUtilities.AppStateObserver)
  @objc dynamic public func applicationDidEnterBackgroundNotification(_ appStateObserver: BanubaUtilities.AppStateObserver)
  @objc dynamic public func applicationWillEnterForeground(_ appStateObserver: BanubaUtilities.AppStateObserver)
  @objc dynamic public func applicationWillTerminateNotification(_ appStateObserver: BanubaUtilities.AppStateObserver)
}
extension UIKit.UITouch {
  @_Concurrency.MainActor @preconcurrency public var id: Swift.Int64 {
    get
  }
}
public enum RenderBehavior {
  case fullScreen
  case verticalSplitUp
  case verticalSplitDown
  case horizontalSplitLeft
  case horizontalSplitRight
  case pip
  case multiCamMixer
  public static func == (a: BanubaSdk.RenderBehavior, b: BanubaSdk.RenderBehavior) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
extension ObjectiveC.NSObject {
  public func performSync(onThread: Foundation.Thread?, block: @escaping @convention(block) () -> Swift.Void)
  public func performAsync(onThread: Foundation.Thread?, block: @escaping @convention(block) () -> Swift.Void)
}
public protocol PIPShape : AnyObject {
  var size: CoreFoundation.CGSize { get }
  var data: Swift.UnsafeMutablePointer<Swift.UInt8> { get }
}
public protocol PIPShapeable {
  func set(shape: (any BanubaSdk.PIPShape)?)
  func set(shapeType: BanubaSdk.PIPShapeBuilder.PIPShapeType)
}
@_hasMissingDesignatedInitializers public class PIPShapeBuilder {
  public enum PIPShapeType : Swift.Equatable {
    case none
    case oval
    case circle
    case roundRect(radius: CoreFoundation.CGFloat)
    case roundSquare(radius: CoreFoundation.CGFloat)
    public static func == (a: BanubaSdk.PIPShapeBuilder.PIPShapeType, b: BanubaSdk.PIPShapeBuilder.PIPShapeType) -> Swift.Bool
  }
  public static func buildShape(size: CoreFoundation.CGSize, path: CoreGraphics.CGPath) -> any BanubaSdk.PIPShape
  @objc deinit
}
extension BNBSdkCore.BNBFrameData {
  public class func create(cvBuffer: CoreVideo.CVPixelBuffer, faceOrientation: Swift.Int = 0, cameraOrientation: BNBSdkCore.BNBCameraOrientation = .deg90, requireMirroring: Swift.Bool = false, fieldOfView: Swift.Float = 60) -> BNBSdkCore.BNBFrameData?
}
@_inheritsConvenienceInitializers @_hasMissingDesignatedInitializers @objc @_Concurrency.MainActor @preconcurrency public class EffectPlayerView : UIKit.UIView {
  @objc @_Concurrency.MainActor @preconcurrency public var isDoubleTapHandlingEnabled: Swift.Bool {
    @objc get
    @objc set
  }
  @_Concurrency.MainActor @preconcurrency @objc override dynamic public init(frame: CoreFoundation.CGRect)
  @_Concurrency.MainActor @preconcurrency @objc override dynamic public class var layerClass: Swift.AnyClass {
    @objc get
  }
  @_Concurrency.MainActor @preconcurrency @objc override dynamic public func touchesBegan(_ touches: Swift.Set<UIKit.UITouch>, with event: UIKit.UIEvent?)
  @_Concurrency.MainActor @preconcurrency @objc override dynamic public func touchesMoved(_ touches: Swift.Set<UIKit.UITouch>, with event: UIKit.UIEvent?)
  @_Concurrency.MainActor @preconcurrency @objc override dynamic public func touchesEnded(_ touches: Swift.Set<UIKit.UITouch>, with event: UIKit.UIEvent?)
  @_Concurrency.MainActor @preconcurrency @objc override dynamic public func touchesCancelled(_ touches: Swift.Set<UIKit.UITouch>, with event: UIKit.UIEvent?)
  @objc @_Concurrency.MainActor @preconcurrency public func onLongTapGesture(gesture: UIKit.UITapGestureRecognizer)
  @objc @_Concurrency.MainActor @preconcurrency public func onDoubleTapGesture(gesture: UIKit.UITapGestureRecognizer)
  @objc @_Concurrency.MainActor @preconcurrency public func onScaleGesture(gesture: UIKit.UIPinchGestureRecognizer)
  @objc @_Concurrency.MainActor @preconcurrency public func onRotationGesture(gesture: UIKit.UIRotationGestureRecognizer)
  @objc @_Concurrency.MainActor @preconcurrency public func onSwipeGesture(gesture: UIKit.UISwipeGestureRecognizer)
  @objc deinit
}
@objc public protocol OutputServicing {
  @objc func configureWatermark(_ watermarkInfo: BanubaSdk.WatermarkInfo)
  @objc func takeSnapshot(configuration: BanubaSdk.OutputConfiguration, handler: @escaping (UIKit.UIImage?) -> Swift.Void)
  @objc func removeWatermark()
  @objc func startVideoCapturing(fileURL: Foundation.URL?, externalAudioConfiguration: BanubaVideoEditorCore.ExternalAudioConfiguration?, progress: ((CoreMedia.CMTime) -> Swift.Void)?, didStart: (() -> Swift.Void)?, shouldSkipFrame: (() -> Swift.Bool)?, isFirstRun: Swift.Bool, periodicProgressTimeInterval: Foundation.TimeInterval, totalDuration: Foundation.TimeInterval, configuration: BanubaSdk.OutputConfiguration, completion: @escaping (Swift.Bool, (any Swift.Error)?) -> Swift.Void)
  @objc func stopVideoCapturing(cancel: Swift.Bool)
  @objc func reset()
  @objc func hasDiskCapacityForRecording() -> Swift.Bool
  @objc func startMuteEffectSoundIfNeeded()
  @objc func stopMuteEffectSound()
  @objc var isRecording: Swift.Bool { get }
  @objc var videoSize: CoreFoundation.CGSize { get set }
  @objc var cropOffsetY: Swift.Int { get set }
}
@objc public class OutputConfiguration : ObjectiveC.NSObject {
  @objc final public let applyWatermark: Swift.Bool
  @objc final public let adjustDeviceOrientation: Swift.Bool
  @objc final public let mirrorFrontCamera: Swift.Bool
  @objc final public let useHEVCCodecIfPossible: Swift.Bool
  @objc public init(applyWatermark: Swift.Bool, adjustDeviceOrientation: Swift.Bool, mirrorFrontCamera: Swift.Bool, useHEVCCodecIfPossible: Swift.Bool)
  @objc public static var defaultConfiguration: BanubaSdk.OutputConfiguration {
    @objc get
  }
  @objc deinit
}
@objc @_hasMissingDesignatedInitializers public class PIPShapeDrawer : ObjectiveC.NSObject {
  @objc deinit
}
extension BanubaSdk.PIPShapeDrawer : BanubaSdk.PIPShapeable {
  public func set(shape: (any BanubaSdk.PIPShape)?)
  public func set(shapeType: BanubaSdk.PIPShapeBuilder.PIPShapeType)
}
@objc public protocol InputServicing : BanubaSdk.AudioCapturing, BanubaSdk.CameraServicing, BanubaSdk.CameraZoomable {
}
public typealias RotateCameraCallBack = () -> ()
@objc public protocol CameraServicing {
  @objc var delegate: (any BanubaSdk.InputServiceDelegate)? { get set }
  @objc var isFrontCamera: Swift.Bool { get }
  @objc var isPhotoCameraSession: Swift.Bool { get }
  @objc var currentCameraSessionType: BanubaSdk.CameraSessionType { get }
  @objc var exposurePointOfInterest: CoreFoundation.CGPoint { get }
  @objc var flipCamera: Swift.Bool { get set }
  @objc var cameraVideoOutput: AVFoundation.AVCaptureVideoDataOutput? { get }
  @objc var systemPressureStateLevel: Swift.String { get }
  @objc var isMultiCamSupported: Swift.Bool { get }
  @objc var isMultiCamEnabled: Swift.Bool { get set }
  @objc func setupCamera()
  @objc func startCamera(_ completion: @escaping () -> Swift.Void)
  @objc func stopCamera()
  @objc func releaseAudioCaptureSession()
  @objc func setCameraSessionType(_ type: BanubaSdk.CameraSessionType)
  @objc func setCameraSessionType(_ type: BanubaSdk.CameraSessionType, completion: @escaping BanubaSdk.RotateCameraCallBack)
  @objc func setCameraSessionType(_ type: BanubaSdk.CameraSessionType, zoomFactor: Swift.Float, completion: @escaping BanubaSdk.RotateCameraCallBack)
  @objc func focus(at point: CoreFoundation.CGPoint, useContinuousDetection: Swift.Bool)
  @objc func setTorch(mode: AVFoundation.AVCaptureDevice.TorchMode) -> AVFoundation.AVCaptureDevice.TorchMode
  @objc func toggleTorch() -> AVFoundation.AVCaptureDevice.TorchMode
  @objc func initiatePhotoCapture(cameraSettings: BanubaSdk.CameraPhotoSettings, completion: @escaping (CoreVideo.CVImageBuffer?, BNBSdkCore.BNBFrameData?) -> Swift.Void)
  @objc func switchCamera(to type: BanubaSdk.CameraSessionType, completion: @escaping BanubaSdk.RotateCameraCallBack)
}
extension BanubaSdk.CameraServicing {
  public func startCamera()
}
@objc public protocol AudioCapturing {
  @objc func startAudioCapturing()
  @objc func stopAudioCapturing()
}
@objc public protocol CameraZoomable {
  @objc var currentFieldOfView: Swift.Float { get }
  @objc var isZoomFactorAdjustable: Swift.Bool { get }
  @objc var minZoomFactor: Swift.Float { get }
  @objc var maxZoomFactor: Swift.Float { get }
  @objc var zoomFactor: Swift.Float { get }
  @objc var defaultZoom: Swift.Float { get }
  @objc func setZoomFactor(_ zoomFactor: Swift.Float) -> Swift.Float
}
@objc public protocol InputServiceDelegate {
  @objc func push(cvBuffer: CoreVideo.CVPixelBuffer, isMainCamera: Swift.Bool)
  @objc func push(cmBuffer: CoreMedia.CMSampleBuffer)
}
@objc public enum CameraSessionType : Swift.Int {
  case FrontCameraVideoSession = 0
  case BackCameraVideoSession = 1
  case FrontCameraPhotoSession = 2
  case BackCameraPhotoSession = 3
  public init?(rawValue: Swift.Int)
  public typealias RawValue = Swift.Int
  public var rawValue: Swift.Int {
    get
  }
}
@objc public class CameraPhotoSettings : ObjectiveC.NSObject {
  @objc final public let photoQualityPrioritization: AVFoundation.AVCapturePhotoOutput.QualityPrioritization
  @objc final public let flashMode: AVFoundation.AVCaptureDevice.FlashMode
  @objc public init(photoQualityPrioritization: AVFoundation.AVCapturePhotoOutput.QualityPrioritization, flashMode: AVFoundation.AVCaptureDevice.FlashMode)
  @objc deinit
}
extension BanubaSdk.CameraSessionType {
  public var isFrontCamera: Swift.Bool {
    get
  }
  public var isPhotoMode: Swift.Bool {
    get
  }
}
extension BanubaSdk.CameraServicing {
  public func toggleCamera(completion: @escaping BanubaSdk.RotateCameraCallBack)
}
@objc extension UIKit.UIImage {
  @objc convenience dynamic public init?(bgraDataNoCopy: Foundation.NSData, width: Swift.Int, height: Swift.Int)
  @objc dynamic public func makeBgraPixelBuffer() -> CoreVideo.CVPixelBuffer?
}
@_inheritsConvenienceInitializers @objc public class MaskPostprocessingService : ObjectiveC.NSObject {
  @objc override dynamic public init()
  @objc deinit
}
extension BanubaSdk.MaskPostprocessingService : BanubaVideoEditorCore.SDKMaskPostprocessServicing {
  @objc dynamic public func processVideoFrame(_ from: CoreVideo.CVPixelBuffer, to: CoreVideo.CVPixelBuffer, time: CoreMedia.CMTime)
  @objc dynamic public func loadEffect(path: Swift.String)
  @objc dynamic public func unloadEffect()
}
@objc public enum RenderContentMode : Swift.Int {
  case resizeAspect
  case resizeAspectFill
  case resize
  public init?(rawValue: Swift.Int)
  public typealias RawValue = Swift.Int
  public var rawValue: Swift.Int {
    get
  }
}
public protocol SnapshotProvider {
  func makeSnapshotWithSettings(_ settings: BanubaVideoEditorCore.VEOutputSettings, watermarkPixelBuffer: CoreVideo.CVPixelBuffer?) -> UIKit.UIImage?
}
public protocol PixelBufferProvider {
  func makeVideoPixelBuffer() -> CoreVideo.CVPixelBuffer?
}
@_hasMissingDesignatedInitializers @objc public class RenderTarget : BanubaSdk.PIPShapeDrawer, BanubaSdk.SnapshotProvider, BanubaSdk.PixelBufferProvider {
  public var renderBehaviour: BanubaSdk.RenderBehavior
  public var pipPlayer: BanubaSdk.PIPPlayer?
  public var pipPlayerRelativeLeftTopPoint: CoreFoundation.CGPoint
  public var multiCamMixer: BanubaSdk.MultiCamMixer?
  public var multiCamMixerRelativeLeftTopPoint: CoreFoundation.CGPoint
  public var splitRenderOffset: CoreFoundation.CGPoint
  public var playerRect: CoreFoundation.CGRect {
    get
  }
  public var pipRect: CoreFoundation.CGRect? {
    get
  }
  public var shouldZoomPipImage: Swift.Bool
  public func setSplitRender(rect: CoreFoundation.CGRect, offset: CoreFoundation.CGPoint)
  @objc deinit
  @objc public func makeVideoPixelBuffer() -> CoreVideo.CVPixelBuffer?
  @objc public func makeSnapshotWithSettings(_ settings: BanubaVideoEditorCore.VEOutputSettings, watermarkPixelBuffer: CoreVideo.CVPixelBuffer?) -> UIKit.UIImage?
  @objc public func activate()
  @objc public func present(_ willPresentHandler: ((CoreVideo.CVPixelBuffer?) -> Swift.Void)?)
}
extension BanubaSdk.EffectPlayerRenderMode : Swift.Equatable {}
extension BanubaSdk.EffectPlayerRenderMode : Swift.Hashable {}
extension BanubaSdk.EffectPlayerRenderMode : Swift.RawRepresentable {}
extension BanubaSdk.BanubaCameraModule.MethodInJson : Swift.Equatable {}
extension BanubaSdk.BanubaCameraModule.MethodInJson : Swift.Hashable {}
extension BanubaSdk.BanubaCameraModule.MethodInJson : Swift.RawRepresentable {}
extension BanubaSdk.WatermarkCornerPosition : Swift.Equatable {}
extension BanubaSdk.WatermarkCornerPosition : Swift.Hashable {}
extension BanubaSdk.WatermarkCornerPosition : Swift.RawRepresentable {}
extension BanubaSdk.RenderBehavior : Swift.Equatable {}
extension BanubaSdk.RenderBehavior : Swift.Hashable {}
extension BanubaSdk.CameraSessionType : Swift.Equatable {}
extension BanubaSdk.CameraSessionType : Swift.Hashable {}
extension BanubaSdk.CameraSessionType : Swift.RawRepresentable {}
extension BanubaSdk.RenderContentMode : Swift.Equatable {}
extension BanubaSdk.RenderContentMode : Swift.Hashable {}
extension BanubaSdk.RenderContentMode : Swift.RawRepresentable {}
